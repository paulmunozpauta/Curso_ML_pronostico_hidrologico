{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PWYheXgMaUc9",
      "metadata": {
        "id": "PWYheXgMaUc9"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/ML_course_IUPWARE2025"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y6CoUb5OXNnT",
      "metadata": {
        "id": "y6CoUb5OXNnT"
      },
      "source": [
        "# Curso: Machine Learning para Pron√≥stico Hidrol√≥gico"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cY8Bcd1_ZD8g",
      "metadata": {
        "id": "cY8Bcd1_ZD8g"
      },
      "source": [
        "<div style=\"text-align:center;\">\n",
        "    <img src=\"https://github.com/paulmunozpauta//Curso_ML_pronostico_hidrologico/blob/main/notebooks/static/imgs/Logo_course.png?raw=true\" width=\"300\">\n",
        "    <p style=\"margin-top:10px;\">\n",
        "        Contacto: paul.andres.munoz@gmail.com\n",
        "    </p>\n",
        "    <p><a href=\"https://paulmunozpauta.github.io/paulmunozpauta/index.html\" target=\"_blank\">Website personal</a></p>\n",
        "</div>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VU87K-KEi4ko",
      "metadata": {
        "id": "VU87K-KEi4ko"
      },
      "source": [
        "## ‚úÖ Antes de comenzar: sigue estos 4 pasos para ejecutar el notebook en Google Colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xwSgGGyUjFr0",
      "metadata": {
        "id": "xwSgGGyUjFr0"
      },
      "source": [
        "Paso 1. Clona el repositorio de GitHub con los notebooks y datos del curso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5-sQWZ2Li4Un",
      "metadata": {
        "id": "5-sQWZ2Li4Un"
      },
      "outputs": [],
      "source": [
        "!git clone -- https://github.com/paulmunozpauta/Curso_ML_pronostico_hidrologico.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NWXPzpZhjJSZ",
      "metadata": {
        "id": "NWXPzpZhjJSZ"
      },
      "source": [
        "Paso 2. Accede a la carpeta clonada.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZoxJZnBii4Rk",
      "metadata": {
        "id": "ZoxJZnBii4Rk"
      },
      "outputs": [],
      "source": [
        "ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LsGV4Z0ii4O3",
      "metadata": {
        "id": "LsGV4Z0ii4O3"
      },
      "outputs": [],
      "source": [
        "%cd Curso_ML_pronostico_hidrologico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v3McxR3di4Ml",
      "metadata": {
        "id": "v3McxR3di4Ml"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Equu3RsjN7Q",
      "metadata": {
        "id": "6Equu3RsjN7Q"
      },
      "source": [
        "Paso 3. Configura el entorno para ejecutar el c√≥digo del curso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cada7549",
      "metadata": {
        "id": "cada7549"
      },
      "outputs": [],
      "source": [
        "# Resolver un conflicto con Colab, nueva versi√≥n de numpy\n",
        "!pip uninstall -y numpy\n",
        "# Instalar las versi√≥n de numpy para el curso\n",
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5AexfO4Wi4KA",
      "metadata": {
        "id": "5AexfO4Wi4KA"
      },
      "outputs": [],
      "source": [
        "# Install Poetry\n",
        "!pip install poetry\n",
        "# Disable virtual environment creation (needed for Colab)\n",
        "!poetry config virtualenvs.create false"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ApaBIJBGCitE",
      "metadata": {
        "id": "ApaBIJBGCitE"
      },
      "source": [
        "üîÅ Si la sesi√≥n se reinicia, repite los pasos 2 y 3.\n",
        "‚û°Ô∏è Si no, contin√∫a con el paso 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yyOc52YFjShA",
      "metadata": {
        "id": "yyOc52YFjShA"
      },
      "source": [
        "Paso 4. Instala los paquetes necesarios para el curso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ynP1G37Ui4HZ",
      "metadata": {
        "id": "ynP1G37Ui4HZ"
      },
      "outputs": [],
      "source": [
        "%cd Curso_ML_pronostico_hidrologico\n",
        "!poetry lock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c97a7f7d",
      "metadata": {
        "id": "c97a7f7d"
      },
      "outputs": [],
      "source": [
        "!poetry install --no-root"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KwOYtFTsja8k",
      "metadata": {
        "id": "KwOYtFTsja8k"
      },
      "source": [
        "üß™ Ahora s√≠, empezamos con la parte pr√°ctica del curso\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1ce37e",
      "metadata": {
        "id": "0e1ce37e"
      },
      "source": [
        "# Parte 2: Desarrollo de modelos hidrol√≥gicos con Machine Learning\n",
        "En esta sesi√≥n, vamos a:\n",
        "\n",
        "Desarrollar modelos de pron√≥stico para el caso de la cuenca de monta√±a ‚õ∞Ô∏è\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce59d2de",
      "metadata": {
        "id": "ce59d2de"
      },
      "source": [
        "\n",
        "## Importar bibliotecas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a8a96e",
      "metadata": {
        "id": "c7a8a96e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.dates as dates\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from copy import deepcopy\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "def lagged_dataset(arr, num_steps, additional_arr, new_num_steps):\n",
        "    num_columns = arr.shape[1]\n",
        "    modified_rows = []\n",
        "    excluded_data = []\n",
        "    for i in range(num_steps, arr.shape[0]):\n",
        "        prev_rows = arr[i - num_steps:i]\n",
        "        current_row = arr[i]\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row))\n",
        "        modified_rows.append(new_row)\n",
        "    result_array = np.array(modified_rows)\n",
        "    # Slicing the result_array to match the number of rows in modified_additional_arr\n",
        "    if result_array.shape[0] > additional_arr.shape[0]:\n",
        "        result_array = result_array[result_array.shape[0] - additional_arr.shape[0]:]\n",
        "\n",
        "    modified_rows = []\n",
        "    for i in range(new_num_steps, additional_arr.shape[0]):\n",
        "        prev_rows = additional_arr[i - new_num_steps:i]\n",
        "        current_row = additional_arr[i]\n",
        "        excluded_data.append(current_row[-1])  # Store excluded data\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row[:-1]))  # Exclude last column\n",
        "        modified_rows.append(new_row)\n",
        "\n",
        "    modified_additional_arr = np.array(modified_rows)\n",
        "\n",
        "    # Adjust dimensions by removing rows from result_array or modified_additional_arr\n",
        "    min_rows = min(result_array.shape[0], modified_additional_arr.shape[0])\n",
        "    result_array = result_array[-min_rows:]\n",
        "    modified_additional_arr = modified_additional_arr[-min_rows:]\n",
        "    excluded_data = np.array(excluded_data)[-min_rows:]\n",
        "\n",
        "    # Concatenate result_array and modified_additional_arr\n",
        "    final_result = np.concatenate((result_array, modified_additional_arr), axis=1)\n",
        "\n",
        "    return final_result, np.array(excluded_data)[:, None]\n",
        "\n",
        "def lagged_dataset_pron(arr, num_steps, additional_arr, new_num_steps, lead_time):\n",
        "    num_columns = arr.shape[1]\n",
        "    modified_rows = []\n",
        "    excluded_data = []\n",
        "\n",
        "    for i in range(num_steps, arr.shape[0]):\n",
        "        prev_rows = arr[i - num_steps:i]\n",
        "        current_row = arr[i]\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row))\n",
        "        modified_rows.append(new_row)\n",
        "\n",
        "    result_array = np.array(modified_rows)\n",
        "\n",
        "    # Slicing the result_array to match the number of rows in modified_additional_arr\n",
        "    if result_array.shape[0] > additional_arr.shape[0]:\n",
        "        result_array = result_array[result_array.shape[0] - additional_arr.shape[0]:]\n",
        "\n",
        "    modified_rows = []\n",
        "    for i in range(new_num_steps, additional_arr.shape[0]):\n",
        "        prev_rows = additional_arr[i - new_num_steps:i]\n",
        "        current_row = additional_arr[i]\n",
        "        excluded_data.append(current_row[-1])  # Store excluded data\n",
        "        new_row = np.concatenate((prev_rows.flatten(), current_row))  # Include last column\n",
        "        modified_rows.append(new_row)\n",
        "\n",
        "    modified_additional_arr = np.array(modified_rows)\n",
        "\n",
        "    # Adjust dimensions by removing rows from result_array or modified_additional_arr\n",
        "    min_rows = min(result_array.shape[0], modified_additional_arr.shape[0])\n",
        "    result_array = result_array[-min_rows:]\n",
        "    modified_additional_arr = modified_additional_arr[-min_rows:]\n",
        "    excluded_data = np.array(excluded_data)[-min_rows:]\n",
        "\n",
        "    # Shift excluded_data by lead_time\n",
        "    excluded_data = excluded_data[lead_time:]\n",
        "\n",
        "    # Concatenate result_array and modified_additional_arr\n",
        "    final_result = np.concatenate((result_array, modified_additional_arr), axis=1)\n",
        "\n",
        "    # Resize final_result and excluded_data to have the same number of rows\n",
        "    min_rows = min(final_result.shape[0], excluded_data.shape[0])\n",
        "    final_result = final_result[:min_rows]\n",
        "    excluded_data = excluded_data[:min_rows]\n",
        "\n",
        "    return final_result, np.array(excluded_data)[:, None]\n",
        "\n",
        "\n",
        "def calculate_hydro_metrics(simulations, evaluation):\n",
        "    sim_mean = np.mean(simulations, axis=0, dtype=np.float64)\n",
        "    obs_mean = np.mean(evaluation, dtype=np.float64)\n",
        "\n",
        "    r_num = np.sum((simulations - sim_mean) * (evaluation - obs_mean),\n",
        "                   axis=0, dtype=np.float64)\n",
        "    r_den = np.sqrt(np.sum((simulations - sim_mean) ** 2,\n",
        "                           axis=0, dtype=np.float64)\n",
        "                    * np.sum((evaluation - obs_mean) ** 2,\n",
        "                             dtype=np.float64))\n",
        "    r = r_num / r_den\n",
        "    # calculate error in spread of flow alpha\n",
        "    alpha = np.std(simulations, axis=0) / np.std(evaluation, dtype=np.float64)\n",
        "    # calculate error in volume beta (bias of mean discharge)\n",
        "    beta = (np.sum(simulations, axis=0, dtype=np.float64)\n",
        "            / np.sum(evaluation, dtype=np.float64))\n",
        "    # calculate the Kling-Gupta Efficiency KGE\n",
        "    kge = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
        "    rmse = np.sqrt(np.mean((evaluation - simulations) ** 2,\n",
        "                            axis=0, dtype=np.float64))\n",
        "    pbias = (100 * np.sum(evaluation - simulations, axis=0, dtype=np.float64)\n",
        "              / np.sum(evaluation))\n",
        "    r2 = 1 - (np.sum((evaluation - simulations)**2) / np.sum((evaluation - np.mean(evaluation))**2))\n",
        "    return kge, rmse, pbias, r2\n",
        "np.random.seed(22)\n",
        "random.seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "785a3064",
      "metadata": {
        "id": "785a3064"
      },
      "source": [
        "## Seleccionar carpeta del proyecto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85381a55",
      "metadata": {
        "id": "85381a55"
      },
      "outputs": [],
      "source": [
        "folder = os.getcwd()+'/notebooks/data/'\n",
        "folder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b745e22b",
      "metadata": {
        "id": "b745e22b"
      },
      "source": [
        "## Importar datos de precipitaci√≥n üåßÔ∏è\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f65ceb",
      "metadata": {
        "id": "a9f65ceb"
      },
      "source": [
        "### Precipitaci√≥n satelital üõ∞Ô∏è\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e409de",
      "metadata": {
        "id": "85e409de"
      },
      "source": [
        "\n",
        "Leer datos de la cuenca de monta√±a ‚õ∞Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a895238",
      "metadata": {
        "id": "9a895238",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import satellite precipitation data\n",
        "precipitation_satellite = pd.read_csv(folder + 'PERSIANN-CCS_UTC_daily_catchment_1.csv', sep=',')\n",
        "# Rename columns\n",
        "precipitation_satellite.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
        "# Convert 'Date' column to datetime format (without unnecessary dayfirst=True)\n",
        "precipitation_satellite['Date'] = pd.to_datetime(precipitation_satellite['Date'], format='%Y-%m-%d')\n",
        "# Set 'Date' as the index\n",
        "precipitation_satellite.set_index('Date', inplace=True)\n",
        "# Print first rows to verify\n",
        "print(precipitation_satellite.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4be9d91",
      "metadata": {
        "id": "e4be9d91"
      },
      "outputs": [],
      "source": [
        "precipitation_satellite"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1f5926",
      "metadata": {
        "id": "de1f5926"
      },
      "source": [
        "Calcular la precipitaci√≥n anual üìÜüåßÔ∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf220da3",
      "metadata": {
        "id": "cf220da3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Resample annual precipitation data\n",
        "data_annual = precipitation_satellite.resample('Y', label='right', closed='right').sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "181311c8",
      "metadata": {
        "id": "181311c8"
      },
      "source": [
        "Graficar la precipitaci√≥n anual promedio üìä\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d255b712",
      "metadata": {
        "id": "d255b712"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_annual.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd41dc08",
      "metadata": {
        "id": "dd41dc08"
      },
      "source": [
        "Calcular la precipitaci√≥n anual promedio para todos los p√≠xeles en la cuenca üß©‚õ∞Ô∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423c5bf9",
      "metadata": {
        "id": "423c5bf9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data_annual_average =  data_annual.mean(axis=1)\n",
        "data_annual_average"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "268a4c9d",
      "metadata": {
        "id": "268a4c9d"
      },
      "source": [
        "Graficar la precipitaci√≥n promedio (todos los p√≠xeles) üìà\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77108f4c",
      "metadata": {
        "id": "77108f4c"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_annual_average.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5566822",
      "metadata": {
        "id": "f5566822"
      },
      "source": [
        "Calcular la precipitaci√≥n anual promedio en la cuenca\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158532d0",
      "metadata": {
        "id": "158532d0"
      },
      "outputs": [],
      "source": [
        "data_annual_average.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a04b0b3",
      "metadata": {
        "id": "1a04b0b3"
      },
      "source": [
        "Calcular la precipitaci√≥n mensual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdcc548",
      "metadata": {
        "id": "afdcc548"
      },
      "outputs": [],
      "source": [
        "data_monthly = precipitation_satellite.resample('M',label='right',closed='right').sum()\n",
        "data_monthly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc05667b",
      "metadata": {
        "id": "fc05667b"
      },
      "source": [
        "Calcular la precipitaci√≥n mensual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "599bc0ab",
      "metadata": {
        "id": "599bc0ab"
      },
      "outputs": [],
      "source": [
        "data_monthly_mean_pixels =  data_monthly.mean(axis=1)\n",
        "data_monthly_mean_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc48a367",
      "metadata": {
        "id": "fc48a367"
      },
      "source": [
        "Graficar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59682b5c",
      "metadata": {
        "id": "59682b5c"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(40,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_monthly_mean_pixels.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4698599c",
      "metadata": {
        "id": "4698599c"
      },
      "source": [
        "Calcular la precipitaci√≥n mensual promedio (promedio de todos los p√≠xeles en la cuenca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe79312",
      "metadata": {
        "id": "abe79312"
      },
      "outputs": [],
      "source": [
        "data_monthly_mean= data_monthly_mean_pixels.groupby(data_monthly_mean_pixels.index.month).mean()\n",
        "data_monthly_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9edc31a",
      "metadata": {
        "id": "d9edc31a"
      },
      "source": [
        "Graficar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71489e7f",
      "metadata": {
        "id": "71489e7f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "data_monthly_mean.plot(kind='bar', ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663db72f",
      "metadata": {
        "id": "663db72f"
      },
      "source": [
        "### Importar precipitaci√≥n in-situ üåßÔ∏èüìç\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f74626f",
      "metadata": {
        "id": "9f74626f"
      },
      "source": [
        "Usemos tres pluvi√≥metros instalados dentro de la cuenca"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358feba1",
      "metadata": {
        "id": "358feba1"
      },
      "source": [
        "#### Para el pluvi√≥metro 1 üåßÔ∏è\n",
        "Importar y preprocesar los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed797176",
      "metadata": {
        "id": "ed797176"
      },
      "outputs": [],
      "source": [
        "folder_pcp_1 = folder+'Rain_gauge_1/'\n",
        "df_pcp_1= pd.read_table(folder_pcp_1+'Rain_gauge_1.csv', sep=',')\n",
        "df_pcp_1.rename(columns={'Texas_tip_corrected_mm':'Pluvi√≥metro_1'},inplace=True)\n",
        "df_pcp_1.columns\n",
        "df_pcp_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24af0132",
      "metadata": {
        "id": "24af0132"
      },
      "source": [
        "Operaciones para organizar la informaci√≥n en un dataframe manejable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5cf6d5",
      "metadata": {
        "id": "9c5cf6d5"
      },
      "outputs": [],
      "source": [
        "# Rename the column 'Date_yy/mm/dd_hh:mm:ss' to 'Date'\n",
        "df_pcp_1.rename(columns={'Date_yy/mm/dd_hh:mm:ss': 'Date'}, inplace=True)\n",
        "# Convert the 'Date' column to datetime format\n",
        "df_pcp_1['Date'] = df_pcp_1['Date'].apply(lambda x: pd.to_datetime(x, dayfirst=True))\n",
        "# Set the 'Date' column as the index\n",
        "df_pcp_1.set_index('Date', inplace=True)\n",
        "df_pcp_1 = df_pcp_1[~df_pcp_1.index.duplicated(keep='first')]\n",
        "\n",
        "df_pcp_1 = df_pcp_1.sort_index()\n",
        "\n",
        "df_pcp_1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5c639a",
      "metadata": {
        "id": "6d5c639a"
      },
      "source": [
        "Graficar el a√±o 2020 de la serie de precipitaci√≥n importada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b21deec",
      "metadata": {
        "id": "6b21deec"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_1.loc['2020'].plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1f9ff66",
      "metadata": {
        "id": "f1f9ff66"
      },
      "source": [
        "Graficar la precipitaci√≥n acumulada de 2020 a partir de la serie temporal importada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1af4791",
      "metadata": {
        "id": "c1af4791"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_1.loc['2020'].cumsum().plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85df75cf",
      "metadata": {
        "id": "85df75cf"
      },
      "source": [
        "#### Para el pluvi√≥metro 2 üåßÔ∏è\n",
        "\n",
        "Importar y preprocesar los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "670a4b09",
      "metadata": {
        "id": "670a4b09"
      },
      "outputs": [],
      "source": [
        "folder_pcp_2 = folder+'Rain_gauge_2/'\n",
        "df_pcp_2= pd.read_table(folder_pcp_2+'Rain_gauge_2.csv', sep=',')\n",
        "df_pcp_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f70661",
      "metadata": {
        "id": "98f70661"
      },
      "source": [
        "Operaciones para crear un dataframe manejable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2873c748",
      "metadata": {
        "id": "2873c748"
      },
      "outputs": [],
      "source": [
        "df_pcp_2['Date'] = df_pcp_2.Date.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
        "df_pcp_2.set_index(df_pcp_2['Date'],inplace=True)\n",
        "df_pcp_2.rename(columns={'Precipitation':'Pluvi√≥metro_2'},inplace=True)\n",
        "df_pcp_2 = df_pcp_2.drop(labels='Date', axis=1)\n",
        "df_pcp_2 = df_pcp_2[~df_pcp_2.index.duplicated(keep='first')]\n",
        "\n",
        "df_pcp_2 = df_pcp_2.sort_index()\n",
        "df_pcp_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e2dd1e4",
      "metadata": {
        "id": "5e2dd1e4"
      },
      "source": [
        "Graficar el a√±o 2020 de la serie importada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c1ea79",
      "metadata": {
        "id": "e5c1ea79"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_2.loc['2020'].plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d543a42",
      "metadata": {
        "id": "2d543a42"
      },
      "source": [
        "Graficar la precipitaci√≥n acumulada del a√±o 2020 a partir de la serie importada\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed87ddb0",
      "metadata": {
        "id": "ed87ddb0"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_2.loc['2020'].cumsum().plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5b01be",
      "metadata": {
        "id": "9b5b01be"
      },
      "source": [
        "#### Para el pluvi√≥metro 3 üåßÔ∏è\n",
        "\n",
        "Importar y preprocesar los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fff3454",
      "metadata": {
        "id": "4fff3454"
      },
      "outputs": [],
      "source": [
        "folder_pcp_3 = folder+'Rain_gauge_3/'\n",
        "df_pcp_3= pd.read_table(folder_pcp_3+'Rain_gauge_3.csv', sep=',')\n",
        "df_pcp_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4364bec1",
      "metadata": {
        "id": "4364bec1"
      },
      "source": [
        "Operaciones para crear un dataframe manejable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc48890",
      "metadata": {
        "id": "1cc48890"
      },
      "outputs": [],
      "source": [
        "df_pcp_3['Fecha'] = df_pcp_3.Fecha.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
        "df_pcp_3.set_index(df_pcp_3['Fecha'],inplace=True)\n",
        "df_pcp_3 = df_pcp_3.drop(labels='Fecha', axis=1)\n",
        "df_pcp_3.rename(columns={'Precipitation':'Pluvi√≥metro_3'},inplace=True)\n",
        "df_pcp_3 = df_pcp_3[~df_pcp_3.index.duplicated(keep='first')]\n",
        "\n",
        "df_pcp_3 = df_pcp_3.sort_index()\n",
        "df_pcp_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d012d8",
      "metadata": {
        "id": "77d012d8"
      },
      "source": [
        "Graficar la precipitaci√≥n del a√±o 2020\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df650fea",
      "metadata": {
        "id": "df650fea"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_3.loc['2020'].plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342ef0a7",
      "metadata": {
        "id": "342ef0a7"
      },
      "source": [
        "Graficar la precipitaci√≥n acumulada del a√±o 2020\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a757f71",
      "metadata": {
        "id": "6a757f71"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_pcp_3.loc['2020'].cumsum().plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_satellite (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab62747",
      "metadata": {
        "id": "bab62747"
      },
      "source": [
        "#### Comparar la precipitaci√≥n in-situ üåßÔ∏èüìç\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b1d1637",
      "metadata": {
        "id": "3b1d1637"
      },
      "source": [
        "Re-muestrear los datos de los 3 pluvi√≥metros a escalas mensuales\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d03db5f",
      "metadata": {
        "id": "1d03db5f"
      },
      "outputs": [],
      "source": [
        "df_pcp_1_monthly = df_pcp_1.resample('M',label='right',closed='right').sum()\n",
        "df_pcp_1_monthly= df_pcp_1_monthly.groupby(df_pcp_1_monthly.index.month).mean()\n",
        "df_pcp_2_monthly = df_pcp_2.resample('M',label='right',closed='right').sum()\n",
        "df_pcp_2_monthly= df_pcp_2_monthly.groupby(df_pcp_2_monthly.index.month).mean()\n",
        "df_pcp_3_monthly = df_pcp_3.resample('M',label='right',closed='right').sum()\n",
        "df_pcp_3_monthly= df_pcp_3_monthly.groupby(df_pcp_3_monthly.index.month).mean()\n",
        "all_pcp_monthly = pd.concat([df_pcp_1_monthly, df_pcp_2_monthly, df_pcp_3_monthly], axis=1)\n",
        "all_pcp_monthly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9225f235",
      "metadata": {
        "id": "9225f235"
      },
      "source": [
        "Graficar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27b08b3",
      "metadata": {
        "id": "a27b08b3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "all_pcp_monthly.plot(kind='bar',ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Precipitation_in situ (mm)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.6), ncol=6)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora comparar con la precipitac√≥n satelital"
      ],
      "metadata": {
        "id": "7XCRO53xCFv7"
      },
      "id": "7XCRO53xCFv7"
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_satellite_mean = precipitation_satellite.resample('M').sum().mean(axis=1)\n",
        "monthly_satellite_mean\n",
        "#Agrupa por mes para obtener un valor promedio por cada mes del a√±o\n",
        "monthly_satellite_mean_by_month = monthly_satellite_mean.groupby(monthly_satellite_mean.index.month).mean()\n",
        "monthly_satellite_mean_by_month\n"
      ],
      "metadata": {
        "id": "a1jlZcS2CEb8"
      },
      "id": "a1jlZcS2CEb8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "# Convertimos los √≠ndices a enteros expl√≠citamente\n",
        "x = list(range(1, 13))\n",
        "\n",
        "# Graficar barras de pluvi√≥metros\n",
        "ax.bar(x, all_pcp_monthly.iloc[:, 0], width=0.2, label='Pluvi√≥metro_1', align='center')\n",
        "ax.bar([i + 0.2 for i in x], all_pcp_monthly.iloc[:, 1], width=0.2, label='Pluvi√≥metro_2', align='center')\n",
        "ax.bar([i + 0.4 for i in x], all_pcp_monthly.iloc[:, 2], width=0.2, label='Pluvi√≥metro_3', align='center')\n",
        "\n",
        "# Graficar la l√≠nea satelital alineada con el primer grupo de barras\n",
        "ax.plot(x, monthly_satellite_mean_by_month.values,\n",
        "        color='black', linewidth=2, linestyle='--', marker='o', label='Sat√©lite (promedio)')\n",
        "\n",
        "# Ejes y leyenda\n",
        "ax.set_xticks([i + 0.2 for i in x])  # Centrar los labels bajo el grupo de barras\n",
        "ax.set_xticklabels(x)\n",
        "ax.set_ylabel('Precipitaci√≥n (mm)')\n",
        "ax.legend(title='Precipitaci√≥n', loc='upper center', bbox_to_anchor=(0.5, -0.4), ncol=4)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nV5s72cQCERd"
      },
      "id": "nV5s72cQCERd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2a67fb1e",
      "metadata": {
        "id": "2a67fb1e"
      },
      "source": [
        "## Importar datos de caudal a la salida de la cuenca de monta√±a üíß\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59bddd9",
      "metadata": {
        "id": "d59bddd9"
      },
      "source": [
        "Importar y organizar los datos de escorrent√≠a en un dataframe manejable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edac2779",
      "metadata": {
        "id": "edac2779",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "folder_runoff = folder+'Runoff_catchment_1/'\n",
        "df_runoff =  pd.read_excel(folder_runoff+'Runoff_catchment_1.xlsx')\n",
        "df_runoff['Fecha'] = df_runoff.Fecha.apply(lambda x: pd.to_datetime(x,dayfirst=True))\n",
        "df_runoff.set_index(df_runoff['Fecha'],inplace=True)\n",
        "df_runoff = df_runoff.drop(labels='Fecha', axis=1)\n",
        "df_runoff"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456ca367",
      "metadata": {
        "id": "456ca367"
      },
      "source": [
        "Graficar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff3879b",
      "metadata": {
        "id": "3ff3879b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "# Assuming dataset is a pandas DataFrame with labeled columns\n",
        "df_runoff.plot(ax=ax)\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title')\n",
        "# Adding a label to the y-axis\n",
        "plt.ylabel('Caudal ($m^3/s$)')\n",
        "# Adjusting the position of the legend\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ada5a4f",
      "metadata": {
        "id": "6ada5a4f"
      },
      "source": [
        "## Combinar datos de precipitaci√≥n (pluvi√≥metros + sat√©lite) y escorrent√≠a para la cuenca üåßÔ∏èüíß‚õ∞Ô∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37efa7ba",
      "metadata": {
        "id": "37efa7ba"
      },
      "outputs": [],
      "source": [
        "df_pcp_1_daily = df_pcp_1.resample('D',label='right',closed='right').sum()\n",
        "df_pcp_2_daily = df_pcp_2.resample('D',label='right',closed='right').sum()\n",
        "df_pcp_3_daily = df_pcp_3.resample('D',label='right',closed='right').sum()\n",
        "df_runoff_daily = df_runoff.resample('D',label='right',closed='right').mean()\n",
        "all_data_daily = pd.concat([df_pcp_1_daily, df_pcp_2_daily, df_pcp_3_daily, precipitation_satellite, df_runoff_daily], axis=1)\n",
        "all_data_daily"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b3e6a2",
      "metadata": {
        "id": "41b3e6a2"
      },
      "source": [
        "### Determinar periodos con datos concurrentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2dd767",
      "metadata": {
        "id": "8a2dd767"
      },
      "outputs": [],
      "source": [
        "concurrent_periods = all_data_daily.dropna().index\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "# Loop through columns\n",
        "for i, col in enumerate(all_data_daily.columns):\n",
        "    # Get a boolean mask where data is not NaN for the current column\n",
        "    mask = ~all_data_daily[col].isna()\n",
        "\n",
        "    # Get the indices of True values in the mask\n",
        "    indices = np.where(mask)[0]\n",
        "\n",
        "    # Plot horizontal lines for continuity\n",
        "    ax.hlines(i, indices[0], indices[-1], colors='0.1', linewidth=5, label=col)\n",
        "\n",
        "# Set y-ticks and labels\n",
        "ax.set_yticks(range(len(all_data_daily.columns)))\n",
        "ax.set_yticklabels(all_data_daily.columns)\n",
        "\n",
        "# Set x-axis label\n",
        "ax.set_xlabel('Date')\n",
        "\n",
        "# Set the x-axis ticks to show years\n",
        "years = pd.to_datetime(all_data_daily.index).year\n",
        "unique_years = np.unique(years)\n",
        "ax.set_xticks(np.arange(len(all_data_daily.index), step=365))\n",
        "ax.set_xticklabels(unique_years,rotation=45)\n",
        "\n",
        "# Add legend\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=11)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc21eafa",
      "metadata": {
        "id": "fc21eafa"
      },
      "source": [
        "## Dividir los datos en periodos de entrenamiento y prueba\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239e7537",
      "metadata": {
        "id": "239e7537"
      },
      "outputs": [],
      "source": [
        "all_data_daily = all_data_daily[~(all_data_daily.isna().any(axis=1) | (all_data_daily.lt(0).any(axis=1)))]\n",
        "input_data_train = np.array(all_data_daily['2013':'2019'].iloc[:,:-1])\n",
        "input_data_test = np.array(all_data_daily['2020':'2021-06'].iloc[:,:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423cd98a",
      "metadata": {
        "id": "423cd98a"
      },
      "outputs": [],
      "source": [
        "input_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6616eafa",
      "metadata": {
        "id": "6616eafa"
      },
      "outputs": [],
      "source": [
        "output_data_train = np.reshape(np.array(all_data_daily['2013':'2019'].iloc[:,-1]),(all_data_daily['2013':'2019'].shape[0],1))\n",
        "output_data_test = np.reshape(np.array(all_data_daily['2020':'2021-06'].iloc[:,-1]),(all_data_daily['2020':'2021-06'].shape[0],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707d9bb8",
      "metadata": {
        "id": "707d9bb8"
      },
      "outputs": [],
      "source": [
        "output_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5501952",
      "metadata": {
        "id": "b5501952"
      },
      "outputs": [],
      "source": [
        "input_data_train_lags, output_data_train_lags= lagged_dataset(input_data_train, 3, output_data_train,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c5bd9b",
      "metadata": {
        "id": "c9c5bd9b"
      },
      "outputs": [],
      "source": [
        "input_data_train_lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec645947",
      "metadata": {
        "id": "ec645947"
      },
      "outputs": [],
      "source": [
        "output_data_train_lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a37b0e",
      "metadata": {
        "id": "16a37b0e"
      },
      "outputs": [],
      "source": [
        "input_data_test_lags, output_data_test_lags= lagged_dataset(input_data_test, 3, output_data_test,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e74788",
      "metadata": {
        "id": "49e74788"
      },
      "outputs": [],
      "source": [
        "input_data_test_lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42cf385",
      "metadata": {
        "id": "f42cf385"
      },
      "outputs": [],
      "source": [
        "output_data_test_lags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae96a3d",
      "metadata": {
        "id": "bae96a3d"
      },
      "source": [
        "## Creaci√≥n y entrenamiento de un modelo Random Forest (sin pron√≥stico)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b78f49",
      "metadata": {
        "id": "f2b78f49"
      },
      "source": [
        "### Definir los hiperpar√°metros del modelo ‚öôÔ∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad963f0f",
      "metadata": {
        "id": "ad963f0f"
      },
      "outputs": [],
      "source": [
        "min_samples_splt=10\n",
        "min_samples_lf=4\n",
        "max_dpth=350\n",
        "n_trees=600\n",
        "max_ft='sqrt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc8e865",
      "metadata": {
        "id": "7dc8e865"
      },
      "source": [
        "### Definir el modelo üß†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23362103",
      "metadata": {
        "id": "23362103"
      },
      "outputs": [],
      "source": [
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=22)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea50d345",
      "metadata": {
        "id": "ea50d345"
      },
      "source": [
        "### Entrenar el modelo üéØ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade3adfc",
      "metadata": {
        "id": "ade3adfc"
      },
      "outputs": [],
      "source": [
        "# Correcting the shape of output_data_train_lags\n",
        "regr = regr.fit(input_data_train_lags, output_data_train_lags.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6bd88b",
      "metadata": {
        "id": "3a6bd88b"
      },
      "source": [
        "### Generar simulaciones para el periodo de entrenamiento üß™\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403bbb8b",
      "metadata": {
        "id": "403bbb8b"
      },
      "outputs": [],
      "source": [
        "simulations_data_train= regr.predict(input_data_train_lags)\n",
        "simulations_data_train= np.reshape(simulations_data_train, (-1, 1))\n",
        "simulations_data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bac04b9",
      "metadata": {
        "id": "7bac04b9"
      },
      "source": [
        "### Generar simulaciones para el periodo de prueba\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edcaf0e3",
      "metadata": {
        "id": "edcaf0e3"
      },
      "outputs": [],
      "source": [
        "#Prediction on unseen data\n",
        "simulations_data_test= regr.predict(input_data_test_lags)\n",
        "simulations_data_test= np.reshape(simulations_data_test, (-1, 1))\n",
        "simulations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf59b53",
      "metadata": {
        "id": "edf59b53"
      },
      "source": [
        "### Evaluaci√≥n del modelo\n",
        "\n",
        "Calcular los coeficientes de correlaci√≥n para los periodos de entrenamiento y prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eee0d34",
      "metadata": {
        "id": "1eee0d34"
      },
      "outputs": [],
      "source": [
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bbbcc7",
      "metadata": {
        "id": "17bbbcc7"
      },
      "source": [
        "## Creaci√≥n y entrenamiento de un modelo Random Forest (con pron√≥stico)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e2609b",
      "metadata": {
        "id": "d4e2609b"
      },
      "source": [
        "### Caso de pron√≥stico a un d√≠a üìÜ‚û°Ô∏è1Ô∏è‚É£\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c825a899",
      "metadata": {
        "id": "c825a899"
      },
      "outputs": [],
      "source": [
        "leadtime = 1\n",
        "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 7, output_data_train,15, lead_time=leadtime)\n",
        "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 7, output_data_test,15, lead_time=leadtime)\n",
        "min_samples_splt=10\n",
        "min_samples_lf=4\n",
        "max_dpth=350\n",
        "n_trees=600\n",
        "max_ft='sqrt'\n",
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=42)\n",
        "regr=regr.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "#Prediction on training data\n",
        "simulations_data_train= regr.predict(input_data_train_lags)\n",
        "simulations_data_train= np.reshape(simulations_data_train, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test= regr.predict(input_data_test_lags)\n",
        "simulations_data_test= np.reshape(simulations_data_test, (-1, 1))\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4faead0",
      "metadata": {
        "id": "a4faead0"
      },
      "source": [
        "### Pron√≥sticos en el periodo de prueba üìä‚è≥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7f3d4c4",
      "metadata": {
        "id": "a7f3d4c4"
      },
      "outputs": [],
      "source": [
        "simulations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5262ad4b",
      "metadata": {
        "id": "5262ad4b"
      },
      "source": [
        "### Evaluaci√≥n usando una combinaci√≥n de m√©tricas de eficiencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9997523",
      "metadata": {
        "id": "e9997523"
      },
      "outputs": [],
      "source": [
        "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test, output_data_test_lags)\n",
        "print(f\"RMSE: {rmse[0]:.4f}\")\n",
        "print(f\"PBias: {pbias[0]:.4f}\")\n",
        "print(f\"KGE: {kge[0]:.4f}\")\n",
        "print(f\"R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63cdf224",
      "metadata": {
        "id": "63cdf224"
      },
      "source": [
        "### Evaluaci√≥n mediante inspecci√≥n visual"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0dd0d7d",
      "metadata": {
        "id": "b0dd0d7d"
      },
      "source": [
        "### Pron√≥sticos de escorrent√≠a a un d√≠a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b541505d",
      "metadata": {
        "id": "b541505d"
      },
      "outputs": [],
      "source": [
        "simulations_data_test = pd.DataFrame(simulations_data_test, columns=['Forecasts'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
        "simulations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a564c026",
      "metadata": {
        "id": "a564c026"
      },
      "source": [
        "### Y las observaciones de escorrent√≠a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72705ac0",
      "metadata": {
        "id": "72705ac0"
      },
      "outputs": [],
      "source": [
        "observations_data_test = pd.DataFrame(output_data_test_lags, columns=['Observations'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
        "observations_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d72102a",
      "metadata": {
        "id": "4d72102a"
      },
      "source": [
        "### Combinar pron√≥sticos y observaciones en un DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c5e0fa",
      "metadata": {
        "id": "a9c5e0fa"
      },
      "outputs": [],
      "source": [
        "testing_period = pd.concat([simulations_data_test, observations_data_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ae60f6",
      "metadata": {
        "id": "e5ae60f6"
      },
      "outputs": [],
      "source": [
        "testing_period"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1bd4499",
      "metadata": {
        "id": "e1bd4499"
      },
      "source": [
        "### Graficar (comparar) pron√≥sticos y observaciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7d3511",
      "metadata": {
        "id": "2d7d3511"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate mean and percentiles\n",
        "mean_obs = testing_period['Observations'].mean()\n",
        "p05 = testing_period['Observations'].quantile(0.05)\n",
        "p95= testing_period['Observations'].quantile(0.95)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Plot forecasts and observations\n",
        "testing_period['Forecasts'].plot(ax=ax, color='red', marker='o', linestyle='', markersize=2, label='Forecasts')\n",
        "testing_period['Observations'].plot(ax=ax, color='black', linestyle='-', label='Observations')\n",
        "\n",
        "# Add horizontal lines for mean and percentiles\n",
        "ax.axhline(mean_obs, color='blue', linestyle='--', linewidth=1, label=f'Mean ({mean_obs:.2f} $m^3/s$)')\n",
        "ax.axhline(p05, color='green', linestyle=':', linewidth=1, label=f'5th Percentile ({p05:.2f} $m^3/s$)')\n",
        "ax.axhline(p95, color='orange', linestyle=':', linewidth=1, label=f'95th Percentile ({p95:.2f} $m^3/s$)')\n",
        "\n",
        "# Add labels and legend\n",
        "ax.set_ylabel('Runoff ($m^3/s$)')\n",
        "ax.legend(loc='upper right')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d9500b",
      "metadata": {
        "id": "86d9500b"
      },
      "source": [
        "### Diagrama de dispersi√≥n de pron√≥sticos y observaciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592c0d40",
      "metadata": {
        "id": "592c0d40"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "\n",
        "# Step 1: Clean the data to handle NaN and Inf values\n",
        "testing_period = testing_period.replace([np.inf, -np.inf], np.nan).dropna(subset=['Observations', 'Forecasts'])\n",
        "\n",
        "# Step 2: Scatter plot data\n",
        "x = testing_period['Observations'].values\n",
        "y = testing_period['Forecasts'].values\n",
        "\n",
        "# Step 3: Create the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Scatter plot for Observations vs Forecasts\n",
        "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, ax=ax)\n",
        "\n",
        "# Step 4: KDE using scipy's gaussian_kde\n",
        "# Create grid for KDE\n",
        "xmin, xmax = x.min(), x.max()\n",
        "ymin, ymax = y.min(), y.max()\n",
        "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
        "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Perform KDE\n",
        "kde = gaussian_kde(np.vstack([x, y]))\n",
        "density = np.reshape(kde(positions).T, xx.shape)\n",
        "\n",
        "# Plot KDE contours\n",
        "ax.contour(xx, yy, density, levels=13, cmap='magma')\n",
        "\n",
        "# Step 5: Add bisector line (y = x)\n",
        "min_val = min(xmin, ymin)\n",
        "max_val = max(xmax, ymax)\n",
        "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
        "\n",
        "# Step 6: Add labels and legend\n",
        "ax.set_xlabel('Observaciones ($m^3/s$)')\n",
        "ax.set_ylabel('Pron√≥sticos ($m^3/s$)')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c527a2",
      "metadata": {
        "id": "28c527a2"
      },
      "source": [
        "## Incluir datos de ENSO\n",
        "\n",
        "https://psl.noaa.gov/gcos_wgsp/Timeseries/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2ed620",
      "metadata": {
        "id": "4c2ed620"
      },
      "source": [
        "Importar datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "324f2665",
      "metadata": {
        "id": "324f2665"
      },
      "outputs": [],
      "source": [
        "# Define the path to\n",
        "folder_nino12 = folder+'ENSO/nino12.long.anom.data.xlsx'\n",
        "folder_nino3 = folder+'ENSO/nino3.long.anom.data.xlsx'\n",
        "folder_nino34 = folder+'ENSO/nino34.long.anom.data.xlsx'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7adbb1d",
      "metadata": {
        "id": "c7adbb1d"
      },
      "outputs": [],
      "source": [
        "nino12 =  pd.read_excel(folder_nino12)\n",
        "nino3 =  pd.read_excel(folder_nino3)\n",
        "nino34 =  pd.read_excel(folder_nino34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3bef597",
      "metadata": {
        "id": "a3bef597"
      },
      "outputs": [],
      "source": [
        "# Melt the DataFrame to convert it to long format\n",
        "nino12_long = nino12.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
        "# Replace '-99.99' values with NaN\n",
        "nino12_long['Data'] = nino12_long['Data'].replace(-99.99, np.nan)\n",
        "# Convert 'Year' and 'Month' to datetime format\n",
        "nino12_long['Date'] = pd.to_datetime(nino12_long['Year'].astype(str) + '-' + nino12_long['Month'], format='%Y-%B')\n",
        "# Set 'Date' as the index\n",
        "nino12_time_series = nino12_long.set_index('Date')[['Data']]\n",
        "# Display the resulting DataFrame\n",
        "nino12_time_series\n",
        "\n",
        "# Melt the DataFrame to convert it to long format\n",
        "nino3_long = nino3.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
        "# Replace '-99.99' values with NaN\n",
        "nino3_long['Data'] = nino3_long['Data'].replace(-99.99, np.nan)\n",
        "# Convert 'Year' and 'Month' to datetime format\n",
        "nino3_long['Date'] = pd.to_datetime(nino3_long['Year'].astype(str) + '-' + nino3_long['Month'], format='%Y-%B')\n",
        "# Set 'Date' as the index\n",
        "nino3_time_series = nino3_long.set_index('Date')[['Data']]\n",
        "# Display the resulting DataFrame\n",
        "nino3_time_series\n",
        "\n",
        "# Melt the DataFrame to convert it to long format\n",
        "nino34_long = nino34.melt(id_vars=['Year'], var_name='Month', value_name='Data')\n",
        "# Replace '-99.99' values with NaN\n",
        "nino34_long['Data'] = nino34_long['Data'].replace(-99.99, np.nan)\n",
        "# Convert 'Year' and 'Month' to datetime format\n",
        "nino34_long['Date'] = pd.to_datetime(nino34_long['Year'].astype(str) + '-' + nino34_long['Month'], format='%Y-%B')\n",
        "# Set 'Date' as the index\n",
        "nino34_time_series = nino34_long.set_index('Date')[['Data']]\n",
        "# Display the resulting DataFrame\n",
        "nino34_time_series"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bca7c59e",
      "metadata": {
        "id": "bca7c59e"
      },
      "source": [
        "### Convertir datos mensuales a datos diarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce06c724",
      "metadata": {
        "id": "ce06c724"
      },
      "outputs": [],
      "source": [
        "nino12_df = nino12_time_series.resample('D').ffill()\n",
        "nino3_df = nino3_time_series.resample('D').ffill()\n",
        "nino34_df = nino34_time_series.resample('D').ffill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1aff46",
      "metadata": {
        "id": "2d1aff46"
      },
      "outputs": [],
      "source": [
        "ENSO_daily = pd.concat([nino12_df,nino3_df,nino34_df], axis=1)\n",
        "ENSO_daily"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0286f86f",
      "metadata": {
        "id": "0286f86f"
      },
      "source": [
        "### Combine all Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "320d4e62",
      "metadata": {
        "id": "320d4e62"
      },
      "outputs": [],
      "source": [
        "all_data_daily_ENSO = pd.concat([all_data_daily, ENSO_daily], axis=1)\n",
        "all_data_daily_ENSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93021149",
      "metadata": {
        "id": "93021149"
      },
      "outputs": [],
      "source": [
        "all_data_daily_ENSO.loc['2013']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89c56f8",
      "metadata": {
        "id": "f89c56f8"
      },
      "source": [
        "### Define training and testing periods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83fbce5e",
      "metadata": {
        "id": "83fbce5e"
      },
      "outputs": [],
      "source": [
        "all_data_daily_ENSO = all_data_daily_ENSO[~(all_data_daily_ENSO.isna().any(axis=1))]\n",
        "all_data_daily_ENSO.shape\n",
        "inputs = all_data_daily_ENSO.drop(all_data_daily_ENSO.columns[-4], axis=1)\n",
        "input_data_train = np.array(inputs['2013':'2019'].iloc[:,:-1])\n",
        "input_data_test = np.array(inputs['2020':'2021-06'].iloc[:,:-1])\n",
        "output_data_train = np.reshape(np.array(all_data_daily_ENSO['2013':'2019'].iloc[:,-4]),(all_data_daily_ENSO['2013':'2019'].shape[0],1))\n",
        "output_data_test = np.reshape(np.array(all_data_daily_ENSO['2020':'2021-06'].iloc[:,-4]),(all_data_daily_ENSO['2020':'2021-06'].shape[0],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2ea0c0",
      "metadata": {
        "id": "6e2ea0c0"
      },
      "outputs": [],
      "source": [
        "input_data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738d2ff8",
      "metadata": {
        "id": "738d2ff8"
      },
      "outputs": [],
      "source": [
        "output_data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16484369",
      "metadata": {
        "id": "16484369"
      },
      "source": [
        "## Desarrollo de modelos de pron√≥stico a un d√≠a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b971e030",
      "metadata": {
        "id": "b971e030"
      },
      "outputs": [],
      "source": [
        "leadtime = 1\n",
        "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 3, output_data_train,15, lead_time=leadtime)\n",
        "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 3, output_data_test,15, lead_time=leadtime)\n",
        "min_samples_splt=10\n",
        "min_samples_lf=4\n",
        "max_dpth=350\n",
        "n_trees=600\n",
        "max_ft='sqrt'\n",
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=22)\n",
        "regr=regr.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "#Prediction on training data\n",
        "simulations_data_train_ENSO= regr.predict(input_data_train_lags)\n",
        "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test_ENSO= regr.predict(input_data_test_lags)\n",
        "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d7c6b18",
      "metadata": {
        "id": "4d7c6b18"
      },
      "source": [
        "### Evaluation with efficiency metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aec896",
      "metadata": {
        "id": "54aec896"
      },
      "outputs": [],
      "source": [
        "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test_ENSO, output_data_test_lags)\n",
        "print(f\"RMSE: {rmse[0]:.4f}\")\n",
        "print(f\"PBias: {pbias[0]:.4f}\")\n",
        "print(f\"KGE: {kge[0]:.4f}\")\n",
        "print(f\"R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5719eb6",
      "metadata": {
        "id": "e5719eb6"
      },
      "source": [
        "### Inspecci√≥n visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e9a93c",
      "metadata": {
        "id": "90e9a93c"
      },
      "outputs": [],
      "source": [
        "simulations_data_test_ENSO = pd.DataFrame(simulations_data_test, columns=['Forecasts'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
        "observations_data_test_ENSO = pd.DataFrame(output_data_test_lags, columns=['Observations'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
        "testing_period_ENSO = pd.concat([simulations_data_test_ENSO, observations_data_test_ENSO], axis=1)\n",
        "\n",
        "\n",
        "# Calculate mean and percentiles for Observations\n",
        "mean_obs = testing_period_ENSO['Observations'].mean()\n",
        "p05 = testing_period_ENSO['Observations'].quantile(0.05)\n",
        "p95 = testing_period_ENSO['Observations'].quantile(0.95)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "# Plot Forecasts and Observations\n",
        "testing_period_ENSO['Forecasts'].plot(ax=ax, color='red', marker='o', linestyle='', markersize=2, label='Forecasts')\n",
        "testing_period_ENSO['Observations'].plot(ax=ax, color='black', linestyle='-', label='Observations')\n",
        "\n",
        "# Add horizontal lines for mean and percentiles\n",
        "ax.axhline(mean_obs, color='blue', linestyle='--', linewidth=1, label=f'Mean ({mean_obs:.2f} $m^3/s$)')\n",
        "ax.axhline(p05, color='green', linestyle=':', linewidth=1, label=f'5th Percentile ({p05:.2f} $m^3/s$)')\n",
        "ax.axhline(p95, color='orange', linestyle=':', linewidth=1, label=f'95th Percentile ({p95:.2f} $m^3/s$)')\n",
        "\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title', loc='upper right')\n",
        "\n",
        "# Adding a label to the y-axis\n",
        "ax.set_ylabel('Caudal ($m^3/s$)')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb4e512",
      "metadata": {
        "id": "afb4e512"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Clean the data (replace inf with NaN, drop NaNs)\n",
        "testing_period_ENSO = testing_period_ENSO.replace([np.inf, -np.inf], np.nan).dropna(subset=['Observations', 'Forecasts'])\n",
        "\n",
        "# Step 2: Scatter plot data\n",
        "x = testing_period_ENSO['Observations'].values\n",
        "y = testing_period_ENSO['Forecasts'].values\n",
        "\n",
        "# Create the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Scatter plot for Observations vs Forecasts\n",
        "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, ax=ax)\n",
        "\n",
        "# Step 3: KDE using scipy's gaussian_kde\n",
        "# Create grid for KDE\n",
        "xmin, xmax = x.min(), x.max()\n",
        "ymin, ymax = y.min(), y.max()\n",
        "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
        "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Perform KDE\n",
        "kde = gaussian_kde(np.vstack([x, y]))\n",
        "density = np.reshape(kde(positions).T, xx.shape)\n",
        "\n",
        "# Plot KDE contours\n",
        "ax.contour(xx, yy, density, levels=13, cmap='magma')\n",
        "\n",
        "# Step 4: Add bisector line (y = x)\n",
        "min_val = min(xmin, ymin)\n",
        "max_val = max(xmax, ymax)\n",
        "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
        "\n",
        "# Step 5: Add labels and legend\n",
        "ax.set_xlabel('Observaciones ($m^3/s$)')\n",
        "ax.set_ylabel('Pron√≥sticos ($m^3/s$)')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252fee0b",
      "metadata": {
        "id": "252fee0b"
      },
      "source": [
        "## Ajuste de hiperpar√°metros del modelo de pron√≥stico ‚öôÔ∏èüîç\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b90ad488",
      "metadata": {
        "id": "b90ad488"
      },
      "source": [
        "### Definir el dominio de b√∫squeda de hiperpar√°metros üéØüìå\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e44fb270",
      "metadata": {
        "id": "e44fb270"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'min_samples_split': [ 10, 20],\n",
        "    'min_samples_leaf': [2, 10],\n",
        "    'max_depth': [100, 300],\n",
        "    'n_estimators': [100, 300],\n",
        "    'max_features': ['sqrt','log2']\n",
        "}\n",
        "\n",
        "# Calculate the total number of combinations\n",
        "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
        "\n",
        "total_combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba6b2a3",
      "metadata": {
        "id": "5ba6b2a3"
      },
      "source": [
        "### Buscar la mejor combinaci√≥n de hiperpar√°metros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2a17f2",
      "metadata": {
        "id": "1f2a17f2"
      },
      "outputs": [],
      "source": [
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=RandomForestRegressor(oob_score=True, n_jobs=-1, warm_start=True),\n",
        "                           param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
        "\n",
        "# Fit the GridSearchCV to your data\n",
        "grid_search.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c23de2f",
      "metadata": {
        "id": "7c23de2f"
      },
      "source": [
        "### Una hiperparametrizaci√≥n m√°s rigurosa üß™‚öôÔ∏è\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dceff9",
      "metadata": {
        "id": "43dceff9"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'min_samples_split': [5, 10, 20],\n",
        "    'min_samples_leaf': [2, 4, 8],\n",
        "    'max_depth': [100, 200, 350],\n",
        "    'n_estimators': [200, 300, 400, 500, 600],\n",
        "    'max_features': ['auto', 'sqrt','log2']\n",
        "}\n",
        "# Calculate the total number of combinations\n",
        "total_combinations = len(list(itertools.product(*param_grid.values())))\n",
        "\n",
        "total_combinations\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=RandomForestRegressor(oob_score=True, n_jobs=-1, warm_start=True),\n",
        "                           param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
        "\n",
        "# Fit the GridSearchCV to your data\n",
        "grid_search.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89af12c4",
      "metadata": {
        "id": "89af12c4"
      },
      "outputs": [],
      "source": [
        "best_model\n",
        "simulations_data_train_ENSO= best_model.predict(input_data_train_lags)\n",
        "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test_ENSO= best_model.predict(input_data_test_lags)\n",
        "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
        "#Nash_Sutcliffe\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51b85a22",
      "metadata": {
        "id": "51b85a22"
      },
      "outputs": [],
      "source": [
        "best_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81fb23d",
      "metadata": {
        "id": "d81fb23d"
      },
      "outputs": [],
      "source": [
        "leadtime = 1\n",
        "input_data_train_lags, output_data_train_lags= lagged_dataset_pron(input_data_train, 3, output_data_train,15, lead_time=leadtime)\n",
        "input_data_test_lags, output_data_test_lags= lagged_dataset_pron(input_data_test, 3, output_data_test,15, lead_time=leadtime)\n",
        "min_samples_splt=10\n",
        "min_samples_lf=2\n",
        "max_dpth=300\n",
        "n_trees=300\n",
        "max_ft='sqrt'\n",
        "regr=RandomForestRegressor(bootstrap=True,min_samples_split=min_samples_splt,\n",
        "                               max_depth=max_dpth,max_features=max_ft,\n",
        "                               min_samples_leaf=min_samples_lf,\n",
        "                               n_estimators=n_trees,oob_score=True,n_jobs=-1,\n",
        "                               warm_start=True,random_state=22)\n",
        "regr=regr.fit(input_data_train_lags, output_data_train_lags.ravel())\n",
        "#Prediction on training data\n",
        "simulations_data_train_ENSO= regr.predict(input_data_train_lags)\n",
        "simulations_data_train_ENSO= np.reshape(simulations_data_train_ENSO, (-1, 1))\n",
        "#Prediction on unseen data\n",
        "simulations_data_test_ENSO= regr.predict(input_data_test_lags)\n",
        "simulations_data_test_ENSO= np.reshape(simulations_data_test_ENSO, (-1, 1))\n",
        "r2_test=regr.score(input_data_test_lags, output_data_test_lags)\n",
        "r2_train=regr.score(input_data_train_lags, output_data_train_lags)\n",
        "print(r2_train,r2_test)\n",
        "kge, rmse, pbias , r2 = calculate_hydro_metrics(simulations_data_test_ENSO, output_data_test_lags)\n",
        "print(f\"RMSE: {rmse[0]:.4f}\")\n",
        "print(f\"PBias: {pbias[0]:.4f}\")\n",
        "print(f\"KGE: {kge[0]:.4f}\")\n",
        "print(f\"R2: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simulations_data_test_ENSO = pd.DataFrame(simulations_data_test, columns=['Forecasts'], index=all_data_daily['2019':'2021-06'].index[-len(simulations_data_test):])\n",
        "observations_data_test_ENSO = pd.DataFrame(output_data_test_lags, columns=['Observations'], index=all_data_daily['2019':'2021-06'].index[-len(output_data_test_lags):])\n",
        "testing_period_ENSO = pd.concat([simulations_data_test_ENSO, observations_data_test_ENSO], axis=1)\n",
        "\n",
        "\n",
        "# Calculate mean and percentiles for Observations\n",
        "mean_obs = testing_period_ENSO['Observations'].mean()\n",
        "p05 = testing_period_ENSO['Observations'].quantile(0.05)\n",
        "p95 = testing_period_ENSO['Observations'].quantile(0.95)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "# Plot Forecasts and Observations\n",
        "testing_period_ENSO['Forecasts'].plot(ax=ax, color='red', marker='o', linestyle='', markersize=2, label='Forecasts')\n",
        "testing_period_ENSO['Observations'].plot(ax=ax, color='black', linestyle='-', label='Observations')\n",
        "\n",
        "# Add horizontal lines for mean and percentiles\n",
        "ax.axhline(mean_obs, color='blue', linestyle='--', linewidth=1, label=f'Mean ({mean_obs:.2f} $m^3/s$)')\n",
        "ax.axhline(p05, color='green', linestyle=':', linewidth=1, label=f'5th Percentile ({p05:.2f} $m^3/s$)')\n",
        "ax.axhline(p95, color='orange', linestyle=':', linewidth=1, label=f'95th Percentile ({p95:.2f} $m^3/s$)')\n",
        "\n",
        "# Adding labels for the legend\n",
        "ax.legend(title='Legend Title', loc='upper right')\n",
        "\n",
        "# Adding a label to the y-axis\n",
        "ax.set_ylabel('Caudal ($m^3/s$)')\n",
        "\n",
        "# Display the"
      ],
      "metadata": {
        "id": "qn48xTF9LRax"
      },
      "id": "qn48xTF9LRax",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clean the data (replace inf with NaN, drop NaNs)\n",
        "testing_period_ENSO = testing_period_ENSO.replace([np.inf, -np.inf], np.nan).dropna(subset=['Observations', 'Forecasts'])\n",
        "\n",
        "# Step 2: Scatter plot data\n",
        "x = testing_period_ENSO['Observations'].values\n",
        "y = testing_period_ENSO['Forecasts'].values\n",
        "\n",
        "# Create the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Scatter plot for Observations vs Forecasts\n",
        "sns.scatterplot(x=x, y=y, color='red', marker='o', s=30, ax=ax)\n",
        "\n",
        "# Step 3: KDE using scipy's gaussian_kde\n",
        "# Create grid for KDE\n",
        "xmin, xmax = x.min(), x.max()\n",
        "ymin, ymax = y.min(), y.max()\n",
        "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
        "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Perform KDE\n",
        "kde = gaussian_kde(np.vstack([x, y]))\n",
        "density = np.reshape(kde(positions).T, xx.shape)\n",
        "\n",
        "# Plot KDE contours\n",
        "ax.contour(xx, yy, density, levels=13, cmap='magma')\n",
        "\n",
        "# Step 4: Add bisector line (y = x)\n",
        "min_val = min(xmin, ymin)\n",
        "max_val = max(xmax, ymax)\n",
        "ax.plot([min_val, max_val], [min_val, max_val], color='blue', linestyle='--', label='Bisector Line')\n",
        "\n",
        "# Step 5: Add labels and legend\n",
        "ax.set_xlabel('Observaciones ($m^3/s$)')\n",
        "ax.set_ylabel('Pron√≥sticos ($m^3/s$)')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UYCRdzscLYxr"
      },
      "id": "UYCRdzscLYxr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}